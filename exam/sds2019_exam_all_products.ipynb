{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "download_logger = logging.getLogger('download')\n",
    "download_logger.setLevel(logging.DEBUG)\n",
    "download_handler = logging.FileHandler('download.log', mode='w')\n",
    "download_handler.setLevel(logging.DEBUG)\n",
    "download_formatter = logging.Formatter('%(asctime)s;%(name)s;%(levelname)s;%(message)s')\n",
    "download_handler.setFormatter(download_formatter)\n",
    "download_logger.addHandler(download_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def ratelimit():\n",
    "    \"A function that handles the rate of your calls.\"\n",
    "    time.sleep(1)\n",
    "\n",
    "class Connector():\n",
    "  def __init__(self,logfile,overwrite_log=False,connector_type='requests',session=False,path2selenium='',n_tries = 5,timeout=30):\n",
    "    \"\"\"This Class implements a method for reliable connection to the internet and monitoring.\n",
    "    It handles simple errors due to connection problems, and logs a range of information for basic quality assessments\n",
    "\n",
    "    Keyword arguments:\n",
    "    logfile -- path to the logfile\n",
    "    overwrite_log -- bool, defining if logfile should be cleared (rarely the case). \n",
    "    connector_type -- use the 'requests' module or the 'selenium'. Will have different since the selenium webdriver does not have a similar response object when using the get method, and monitoring the behavior cannot be automated in the same way.\n",
    "    session -- requests.session object. For defining custom headers and proxies.\n",
    "    path2selenium -- str, sets the path to the geckodriver needed when using selenium.\n",
    "    n_tries -- int, defines the number of retries the *get* method will try to avoid random connection errors.\n",
    "    timeout -- int, seconds the get request will wait for the server to respond, again to avoid connection errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Initialization function defining parameters. \n",
    "    self.n_tries = n_tries # For avoiding triviel error e.g. connection errors, this defines how many times it will retry.\n",
    "    self.timeout = timeout # Defining the maximum time to wait for a server to response.\n",
    "    ## not implemented here, if you use selenium.\n",
    "    if connector_type=='selenium':\n",
    "      assert path2selenium!='', \"You need to specify the path to you geckodriver if you want to use Selenium\"\n",
    "      from selenium import webdriver \n",
    "      ## HIN download the latest geckodriver here: https://github.com/mozilla/geckodriver/releases\n",
    "\n",
    "      assert os.path.isfile(path2selenium),'You need to insert a valid path2selenium the path to your geckodriver. You can download the latest geckodriver here: https://github.com/mozilla/geckodriver/releases'\n",
    "      self.browser = webdriver.Firefox(executable_path=path2selenium) # start the browser with a path to the geckodriver.\n",
    "\n",
    "    self.connector_type = connector_type # set the connector_type\n",
    "    \n",
    "    if session: # set the custom session\n",
    "      self.session = session\n",
    "    else:\n",
    "      self.session = requests.session()\n",
    "    self.logfilename = logfile # set the logfile path\n",
    "    ## define header for the logfile\n",
    "    #header = ['id','project','connector_type','t', 'delta_t', 'url', 'redirect_url','response_size', 'response_code','success','error']\n",
    "\n",
    "    self.project_logger = logging.getLogger()\n",
    "    self.project_logger.setLevel(logging.INFO)\n",
    "\n",
    "    log_mode = 'w' if (overwrite_log or not os.path.isfile(logfile)) else 'a'\n",
    "    self.handler = logging.FileHandler(logfile, mode=log_mode)\n",
    "    self.handler.setLevel(logging.INFO)\n",
    "    self.formatter = logging.Formatter('%(message)s')\n",
    "    self.handler.setFormatter(self.formatter)\n",
    "    self.project_logger.addHandler(self.handler)\n",
    "\n",
    "    if overwrite_log == True or not os.path.isfile(logfile):\n",
    "      # Write header to log file\n",
    "      self.project_logger.info(\n",
    "        msg='{};{};{};{};{};{};{};{};{};{};{}'.format('id','project','connector_type','t', 'delta_t', 'url', 'redirect_url','response_size', 'response_code','success','error'))\n",
    "\n",
    "    with open(logfile,'r') as f: # open file\n",
    "      l = f.readlines()\n",
    "      # Remove lines from log file not beginning with a number\n",
    "      l = list(filter(lambda x: x[0].isalpha(), l))\n",
    "      ## set id\n",
    "      if len(l)<=1:\n",
    "        self.id = 0\n",
    "      else:\n",
    "        self.id = int(l[-1].split(';')[0]) + 1\n",
    "\n",
    "  def log_message(self, project, t, delta_t, url, redirect_url, response_size, response_code, success, error):\n",
    "    return '{};{};{};{};{};{};{};{};{};{};{}'.format(self.id, project, self.connector_type, t, delta_t, url, redirect_url, response_size, response_code, success, error)\n",
    "    \n",
    "  def _inc_id(self):\n",
    "    self.id += 1\n",
    "\n",
    "  def get(self,url,project_name):\n",
    "    \"\"\"Method for connector reliably to the internet, with multiple tries and simple error handling, as well as default logging function.\n",
    "    Input url and the project name for the log (i.e. is it part of mapping the domain, or is it the part of the final stage in the data collection).\n",
    "    \n",
    "    Keyword arguments:\n",
    "    url -- str, url\n",
    "    project_name -- str, Name used for analyzing the log. Use case could be the 'Mapping of domain','Meta_data_collection','main data collection'. \n",
    "    \"\"\"\n",
    "     \n",
    "    project_name = project_name.replace(';','-') # make sure the default csv seperator is not in the project_name.\n",
    "    if self.connector_type=='requests': # Determine connector method.\n",
    "      for _ in range(self.n_tries): # for loop defining number of retries with the requests method.\n",
    "        ratelimit()\n",
    "        t = time.time()\n",
    "        try: # error handling\n",
    "          response = self.session.get(url,timeout = self.timeout) # make get call\n",
    "          err = '' # define python error variable as empty assumming success.\n",
    "          success = True # define success variable\n",
    "          redirect_url = response.url # log current url, after potential redirects \n",
    "          dt = time.time() - t # define delta-time waiting for the server and downloading content.\n",
    "          size = len(response.text) # define variable for size of html content of the response.\n",
    "          response_code = response.status_code # log status code.\n",
    "          ## log...\n",
    "          self._inc_id() # increment call id\n",
    "          self.project_logger.info(\n",
    "              msg=self.log_message(project_name,t,dt,url,redirect_url,size,response_code,success,err))\n",
    "          return response, self.id # return response and unique identifier.\n",
    "\n",
    "        except Exception as e: # define error condition\n",
    "          err = str(e) # python error\n",
    "          response_code = '' # blank response code \n",
    "          success = False # call success = False\n",
    "          size = 0 # content is empty.\n",
    "          redirect_url = '' # redirect url empty \n",
    "          dt =  time.time() - t # define delta t\n",
    "          ## log...\n",
    "          self._inc_id() # increment call_id\n",
    "          self.project_logger.info( \\\n",
    "              msg=self.log_message(project_name,t,dt,url,redirect_url,size,response_code,success,err))\n",
    "    else:\n",
    "      ratelimit()\n",
    "      t = time.time()\n",
    "      self.browser.get(url) # use selenium get method\n",
    "      ## log\n",
    "      self._inc_id() # increment the call_id\n",
    "      err = '' # blank error message\n",
    "      success = '' # success blank\n",
    "      redirect_url = self.browser.current_url # redirect url.\n",
    "      dt = time.time() - t # get time for get method ... NOTE: not necessarily the complete load time.\n",
    "      size = len(self.browser.page_source) # get size of content ... NOTE: not necessarily correct, since selenium works in the background, and could still be loading.\n",
    "      response_code = '' # empty response code.\n",
    "      self.project_logger.info( \\\n",
    "          msg=self.log_message(project_name,t,dt,url,redirect_url,size,response_code,success,err))\n",
    "      # Using selenium it will not return a response object, instead you should call the browser object of the connector.\n",
    "      return self.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reads in a list of product numbers from an excel sheet\n",
    "import pandas as pd\n",
    "\n",
    "df_lmpriser = pd.read_excel('lmpriser_eSundhed_190812.xlsx', sheet_name='DATA', converters={'Varenummer': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATC</th>\n",
       "      <th>Lægemiddel</th>\n",
       "      <th>Varenummer</th>\n",
       "      <th>Pakning</th>\n",
       "      <th>Styrke</th>\n",
       "      <th>Form</th>\n",
       "      <th>Firma</th>\n",
       "      <th>Indikator</th>\n",
       "      <th>20140623</th>\n",
       "      <th>20140707</th>\n",
       "      <th>...</th>\n",
       "      <th>20190408</th>\n",
       "      <th>20190422</th>\n",
       "      <th>20190506</th>\n",
       "      <th>20190520</th>\n",
       "      <th>20190603</th>\n",
       "      <th>20190617</th>\n",
       "      <th>20190701</th>\n",
       "      <th>20190715</th>\n",
       "      <th>20190729</th>\n",
       "      <th>20190812</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01AA01</td>\n",
       "      <td>Bifluorid</td>\n",
       "      <td>042846</td>\n",
       "      <td>4 g + solvens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dentalsuspension</td>\n",
       "      <td>Voco</td>\n",
       "      <td>AIP</td>\n",
       "      <td>407.36</td>\n",
       "      <td>407.36</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01AA01</td>\n",
       "      <td>Bifluorid</td>\n",
       "      <td>042846</td>\n",
       "      <td>4 g + solvens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dentalsuspension</td>\n",
       "      <td>Voco</td>\n",
       "      <td>AUP</td>\n",
       "      <td>568.40</td>\n",
       "      <td>568.40</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01AA01</td>\n",
       "      <td>Bifluorid</td>\n",
       "      <td>042846</td>\n",
       "      <td>4 g + solvens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dentalsuspension</td>\n",
       "      <td>Voco</td>\n",
       "      <td>DDD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01AA01</td>\n",
       "      <td>Bifluorid</td>\n",
       "      <td>042846</td>\n",
       "      <td>4 g + solvens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dentalsuspension</td>\n",
       "      <td>Voco</td>\n",
       "      <td>AUP_pr_DDD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01AA01</td>\n",
       "      <td>Bifluorid</td>\n",
       "      <td>043158</td>\n",
       "      <td>10 g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dentalsuspension</td>\n",
       "      <td>Voco</td>\n",
       "      <td>AIP</td>\n",
       "      <td>602.07</td>\n",
       "      <td>602.07</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ATC Lægemiddel Varenummer        Pakning Styrke              Form  \\\n",
       "0  A01AA01  Bifluorid     042846  4 g + solvens    NaN  dentalsuspension   \n",
       "1  A01AA01  Bifluorid     042846  4 g + solvens    NaN  dentalsuspension   \n",
       "2  A01AA01  Bifluorid     042846  4 g + solvens    NaN  dentalsuspension   \n",
       "3  A01AA01  Bifluorid     042846  4 g + solvens    NaN  dentalsuspension   \n",
       "4  A01AA01  Bifluorid     043158           10 g    NaN  dentalsuspension   \n",
       "\n",
       "  Firma   Indikator  20140623  20140707  ...  20190408  20190422  20190506  \\\n",
       "0  Voco         AIP    407.36    407.36  ...       NaN       NaN       NaN   \n",
       "1  Voco         AUP    568.40    568.40  ...       NaN       NaN       NaN   \n",
       "2  Voco         DDD       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "3  Voco  AUP_pr_DDD       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "4  Voco         AIP    602.07    602.07  ...       NaN       NaN       NaN   \n",
       "\n",
       "   20190520  20190603  20190617  20190701  20190715  20190729  20190812  \n",
       "0       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "3       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lmpriser.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    042846\n",
       "1    042846\n",
       "2    042846\n",
       "3    042846\n",
       "4    043158\n",
       "Name: Varenummer, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy product numbers into a dataframe\n",
    "df_product_numbers = df_lmpriser['Varenummer'].copy()\n",
    "# Delete original dataframe to save memory\n",
    "del df_lmpriser\n",
    "# Peak into the dataframe\n",
    "df_product_numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure unique product numbers\n",
    "product_number_array = df_product_numbers.unique()\n",
    "# Split the product number\n",
    "product_number_arrays = np.array_split(product_number_array, 3)\n",
    "# Insert the correct index here, it defines which set of product numbers to process\n",
    "INDEX = 1\n",
    "# raise NotImplementedError\n",
    "\n",
    "df_product_numbers = pd.Series(product_number_arrays[INDEX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    075227\n",
       "1    101812\n",
       "2    182729\n",
       "3    372663\n",
       "4    561154\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product_numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all product numbers in \"our\" slice of the product numbers\n",
    "product_numbers_slice = df_product_numbers[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5418,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_numbers_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = Connector('med-prices.log', overwrite_log=True)\n",
    "\n",
    "def get_product_details(product_number):\n",
    "    details_url = 'http://api.medicinpriser.dk/v1/produkter/detaljer/{}?format=json'\n",
    "    response, _ = conn.get(details_url.format(product_number), 'med-scrape')\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by defining a Project name\n",
    "project = 'medicin_prices'\n",
    "import os # generel package for interacting with the system\n",
    "# among other things automate folder creation\n",
    "def maybe_create_dir(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "maybe_create_dir(project)\n",
    "\n",
    "subfolders = ['raw_data','parsed_data']\n",
    "\n",
    "raw_data = os.path.join(project, subfolders[0])\n",
    "parsed_data = os.path.join(project, subfolders[1])\n",
    "\n",
    "for directory in subfolders: \n",
    "    maybe_create_dir(os.path.join(project, directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def dump_json(product):\n",
    "    vnr = product['Varenummer']\n",
    "    file_path = os.path.join(raw_data, vnr + '.json')\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(product, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import time\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "driver = webdriver.Firefox(options=options, executable_path='./geckodriver')\n",
    "\n",
    "def get_medication_price_grid_html(vnr: str, sleep_for=20):\n",
    "    # Create base_url based on vnr\n",
    "    base_url = 'https://medicinpriser.dk/Default.aspx?id=15&vnr=' + vnr\n",
    "    # Fetch the base_url using the firefox webdriver\n",
    "    driver.get(base_url)\n",
    "    # Find the price development link\n",
    "    price_development = driver.find_element_by_id(\"ctl00_TopBar_Pridudvikling\")\n",
    "    # Click the price development link\n",
    "    price_development.click()\n",
    "    # Find the date_from input box\n",
    "    date_from_input = driver.find_element_by_id('ctl00_ctl07_ctl00_DateFrom')\n",
    "    # Click the date_from input field\n",
    "    date_from_input.click()\n",
    "    # Clear the date_from input field\n",
    "    date_from_input.clear()\n",
    "    # Send the '01-01-1998' key stroke to the date_from input field\n",
    "    date_from_input.send_keys('01-01-1998')\n",
    "    # Send key <enter> stroke to the date_from input field\n",
    "    date_from_input.send_keys(Keys.ENTER)\n",
    "    # Submit the content of the date_from input field\n",
    "    date_from_input.submit()\n",
    "    # Sleep for sleep_for seconds (default=20)\n",
    "    time.sleep(sleep_for)\n",
    "    # Copy the page_source into a string var\n",
    "    return_str = driver.page_source\n",
    "    # Return the string var to caller\n",
    "    return return_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pno_re = re.compile('[0-9]{6}')\n",
    "\n",
    "def rename_columns(df):\n",
    "    pnos = [vnr.group() for vnr in map(pno_re.search, df.columns[2:])]\n",
    "    df.columns = ['datetime', 'tilskudspris'] + pnos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "def get_price_grid(html_table):\n",
    "    soup = bs(html_table)\n",
    "    price_grid_table = soup.findAll('table', attrs={'id': re.compile(r'.*PriceGrid.*')})\n",
    "    if (len(price_grid_table) == 1):\n",
    "        return price_grid_table[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_html(table_html):\n",
    "    return \"<{h}><{b}>{s}</{b}></{h}>\".format(h='html', b='body', s=str(table_html).replace(',', '.').replace('-', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import WebDriverException\n",
    "\n",
    "def get_dataframe(product_number: str, sleep_for=5):\n",
    "    try:\n",
    "        html = get_medication_price_grid_html(product_number, sleep_for=sleep_for)\n",
    "    except WebDriverException as wde:\n",
    "        download_logger.warning(wde)\n",
    "    table = get_price_grid(html)\n",
    "    if table is None:\n",
    "        return None\n",
    "    maybe_table = pd.read_html(make_html(table))\n",
    "    if len(maybe_table) > 0:\n",
    "        df = maybe_table[0]\n",
    "        rename_columns(df)\n",
    "        return df\n",
    "    else:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series(product_number: str, sleep_for=5) -> DataFrame:\n",
    "    try:\n",
    "        html = get_medication_price_grid_html(product_number, sleep_for=sleep_for)\n",
    "    except WebDriverException as wde:\n",
    "        download_logger.warning(wde)\n",
    "    table = get_price_grid(html)\n",
    "    if table is None:\n",
    "        return None\n",
    "    maybe_table = pd.read_html(make_html(table))\n",
    "    if len(maybe_table) > 0:\n",
    "        df = maybe_table[0]\n",
    "        rename_columns(df)\n",
    "        return df[product_number]\n",
    "    else:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_retry(product_number, func, retries=5, sleep_for=5):\n",
    "    tries = 0\n",
    "    downloaded = False\n",
    "    while tries <= retries and not downloaded:\n",
    "        # Increment the number of tries we have used on this product number\n",
    "        tries += 1\n",
    "        product_details = get_product_details(product_number)\n",
    "        if product_details.ok:\n",
    "            product_json = json.loads(product_details.text)\n",
    "            product_number_str = str(product_json['Varenummer'])\n",
    "            df = func(product_number_str, sleep_for=sleep_for*tries)\n",
    "            if df is not None:\n",
    "                downloaded = True\n",
    "                return df\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing(p_no, p_nos, df):\n",
    "    missing = []\n",
    "    for pno in p_nos:\n",
    "        if pno not in df.columns:\n",
    "            missing.append(pno)\n",
    "    return missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_csv_file(product_number) -> bool:\n",
    "    return os.path.isfile(os.path.join(raw_data, product_number + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "retries = 5\n",
    "\n",
    "for product_number in product_numbers_slice:\n",
    "    tries = 0\n",
    "    # Create a product number string\n",
    "    product_number_str = str(product_number)\n",
    "    downloaded = has_csv_file(product_number_str)\n",
    "    while tries <= retries and not downloaded:\n",
    "        # Increment the number of tries we have used on this product number\n",
    "        tries += 1\n",
    "        product_details = get_product_details(product_number)\n",
    "        if product_details.ok:\n",
    "            product_json = json.loads(product_details.text)\n",
    "            dump_json(product_json)\n",
    "        else:\n",
    "            fail_msg = \"Not able to download: {}, response code: {}\".format(product_number_str, product_details.status_code)\n",
    "            download_logger.warning(fail_msg)\n",
    "            print(fail_msg)\n",
    "            break\n",
    "        df = get_dataframe(product_number_str, sleep_for=5*tries)\n",
    "        if df is not None:\n",
    "            if str(df['datetime'].iloc[0]).endswith('1997'):\n",
    "                success_msg = \"Downloaded data for: {}\".format(product_number_str)\n",
    "                download_logger.info(success_msg)\n",
    "                print(success_msg)\n",
    "                downloaded = True\n",
    "            else:\n",
    "                warning_msg = 'Data for {} was incomplete, redownloading'.format(product_number_str)\n",
    "                download_logger.warning(warning_msg)\n",
    "                print(warning_msg)\n",
    "                downloaded = False\n",
    "            substitude_product_numbers = [p['Varenummer'] for p in product_json['Substitutioner']]\n",
    "            missing_product_numbers = find_missing(product_number, substitude_product_numbers, df)\n",
    "            if len(missing_product_numbers) > 0:\n",
    "                missing_msg = \"Downloading missing substitute product: {}\".format(','.join(missing_product_numbers))\n",
    "                download_logger.info(missing_msg)\n",
    "                print(missing_msg)\n",
    "            for number in missing_product_numbers:\n",
    "                missing_series = with_retry(number, get_series)\n",
    "                if missing_series is not None:\n",
    "                    df[number] = missing_series\n",
    "            # Drops rows filled with na\n",
    "            df = df.dropna(axis=0, thresh=2)\n",
    "            # Save the data into an csv file\n",
    "            df.to_csv(os.path.join(raw_data, product_number_str + '.csv'))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
