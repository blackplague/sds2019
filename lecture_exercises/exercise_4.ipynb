{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Set 4: Data Structuring 1\n",
    "\n",
    "*Afternoon, August 13, 2019*\n",
    "\n",
    "In this Exercise Set we will apply some of the basic things we have learned with pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load modules\n",
    "We begin by loading relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exercise Section 4.1: Weather, part 1\n",
    "\n",
    "Some data sources are open and easy to collect data from. They can be 'scraped' as is and they are already in a table format. This Exercise part of exercises is the first part of three that work with weather data, the follow ups are Exercise Sections 6.1 and 7.1. Our source will be National Oceanic and Atmospheric Administration (NOAA) which have a global data collection going back a couple of centuries. This collection is called Global Historical Climatology Network (GHCN). A description of GHCN can be found [here](https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/readme.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **Ex. 4.1.1:** Use Pandas' CSV reader to fetch  daily data weather from 1864 for various stations - available [here](https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/). \n",
    "\n",
    "> *Hint 1*: for compressed files you may need to specify the keyword `compression`.\n",
    "\n",
    "> *Hint 2*: keyword `header` can be specified as the CSV has no column names.\n",
    "\n",
    "> *Hint 3*: Specify the path, as the URL linking directly to the 1864 file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ITE00100550  18640101  TMAX   10 Unnamed: 4 Unnamed: 5  E  Unnamed: 7\n",
      "0      ITE00100550  18640101  TMIN  -23        NaN        NaN  E         NaN\n",
      "1      ITE00100550  18640101  PRCP   25        NaN        NaN  E         NaN\n",
      "2      ASN00079028  18640101  PRCP    0        NaN        NaN  a         NaN\n",
      "3      USC00064757  18640101  PRCP  119        NaN        NaN  F         NaN\n",
      "4      SF000208660  18640101  PRCP    0        NaN        NaN  I         NaN\n",
      "5      ASN00089000  18640101  PRCP    0        NaN        NaN  a         NaN\n",
      "6      SWE00100003  18640101  PRCP    0        NaN        NaN  E         NaN\n",
      "7      ASN00086071  18640101  TMAX  214        NaN        NaN  a         NaN\n",
      "8      ASN00086071  18640101  TMIN  101        NaN        NaN  a         NaN\n",
      "9      ASN00086071  18640101  PRCP    0        NaN        NaN  a         NaN\n",
      "10     USP00CA0003  18640101  PRCP    0        NaN        NaN  F         NaN\n",
      "11     USC00189674  18640101  PRCP    0        NaN        NaN  F         NaN\n",
      "12     USC00144559  18640101  PRCP    0        NaN        NaN  F         NaN\n",
      "13     USC00144559  18640101  SNOW    0        NaN        NaN  F         NaN\n",
      "14     CA006158350  18640101  TMAX   11        NaN        NaN  C         NaN\n",
      "15     CA006158350  18640101  TMIN -133        NaN        NaN  C         NaN\n",
      "16     CA006158350  18640101  PRCP    5        NaN        NaN  C         NaN\n",
      "17     CA006158350  18640101  SNOW    5        NaN        NaN  C         NaN\n",
      "18     HRE00105189  18640101  PRCP  189        NaN        NaN  E         NaN\n",
      "19     ASN00067054  18640101  PRCP   61        NaN        NaN  a         NaN\n",
      "20     ASN00081003  18640101  PRCP    0        NaN        NaN  a         NaN\n",
      "21     ASN00078037  18640101  PRCP    0        NaN        NaN  a         NaN\n",
      "22     ASN00070037  18640101  PRCP    0        NaN        NaN  a         NaN\n",
      "23     EIE00101859  18640101  TMAX   94        NaN        NaN  E         NaN\n",
      "24     EIE00101859  18640101  TMIN   11        NaN        NaN  E         NaN\n",
      "25     EIE00101859  18640101  PRCP   82        NaN        NaN  E         NaN\n",
      "26     ASN00040214  18640101  PRCP    3        NaN        NaN  a         NaN\n",
      "27     BE000006447  18640101  TMAX  -23        NaN        NaN  I         NaN\n",
      "28     BE000006447  18640101  TMIN  -36        NaN        NaN  I         NaN\n",
      "29     AGE00135039  18640101  PRCP    0        NaN        NaN  E         NaN\n",
      "...            ...       ...   ...  ...        ...        ... ..         ...\n",
      "27318  ASN00066062  18641231  TMAX  223        NaN        NaN  a         NaN\n",
      "27319  ASN00066062  18641231  TMIN  172        NaN        NaN  a         NaN\n",
      "27320  ASN00066062  18641231  PRCP   41        NaN        NaN  a         NaN\n",
      "27321  ASN00023000  18641231  PRCP    0        NaN        NaN  a         NaN\n",
      "27322  SW000010537  18641231  PRCP    0        NaN        NaN  E         NaN\n",
      "27323  ASN00022018  18641231  PRCP    0        NaN        NaN  a         NaN\n",
      "27324  AU000005901  18641231  TMAX  -28        NaN        NaN  E         NaN\n",
      "27325  AU000005901  18641231  TMIN  -79        NaN        NaN  E         NaN\n",
      "27326  GM000004204  18641231  TMAX  -34        NaN        NaN  E         NaN\n",
      "27327  GM000004204  18641231  TMIN -119        NaN        NaN  E         NaN\n",
      "27328  GM000004204  18641231  PRCP    0        NaN        NaN  E         NaN\n",
      "27329  ASN00075048  18641231  PRCP    0        NaN        NaN  a         NaN\n",
      "27330  UK000047811  18641231  TMAX   40        NaN        NaN  E         NaN\n",
      "27331  UK000047811  18641231  TMIN  -14        NaN        NaN  E         NaN\n",
      "27332  UK000047811  18641231  PRCP    0        NaN        NaN  E         NaN\n",
      "27333  HR000142360  18641231  PRCP    0        NaN        NaN  E         NaN\n",
      "27334  ASN00084016  18641231  PRCP   18        NaN        NaN  a         NaN\n",
      "27335  ITE00100552  18641231  PRCP    0        NaN        NaN  E         NaN\n",
      "27336  ITE00100553  18641231  PRCP    0        NaN        NaN  E         NaN\n",
      "27337  ITE00105250  18641231  PRCP    0        NaN        NaN  E         NaN\n",
      "27338  USP00CA0001  18641231  PRCP  157        NaN        NaN  F         NaN\n",
      "27339  ASN00090015  18641231  TMAX  239        NaN        NaN  a         NaN\n",
      "27340  ASN00090015  18641231  TMIN  128        NaN        NaN  a         NaN\n",
      "27341  UK000056225  18641231  TMAX   16        NaN        NaN  E         NaN\n",
      "27342  UK000056225  18641231  TMIN  -19        NaN        NaN  E         NaN\n",
      "27343  UK000056225  18641231  PRCP    3        NaN        NaN  E         NaN\n",
      "27344  ASN00026026  18641231  PRCP    0        NaN        NaN  a         NaN\n",
      "27345  ASN00089049  18641231  PRCP    0        NaN        NaN  a         NaN\n",
      "27346  SZ000006717  18641231  TMAX  -62        NaN        NaN  G         NaN\n",
      "27347  SZ000006717  18641231  TMIN -105        NaN        NaN  G         NaN\n",
      "\n",
      "[27348 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.1]\n",
    "url = 'https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/1864.csv.gz'\n",
    "test = pd.read_csv(url, header=0, compression='gzip')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **Ex. 4.1.2:** Structure your weather DataFrame by using only the relevant columns (station identifier, data, observation type, observation value), rename them. Make sure observations are correctly formated (how many decimals should we add? one?).\n",
    "\n",
    "> *Hint:* rename can be done with `df.columns=COLS` where `COLS` is a list of column names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     StationId      Date ObsType  ObsValue\n",
      "0  ITE00100550  18640101    TMIN       -23\n",
      "1  ITE00100550  18640101    PRCP        25\n",
      "2  ASN00079028  18640101    PRCP         0\n",
      "3  USC00064757  18640101    PRCP       119\n",
      "4  SF000208660  18640101    PRCP         0\n",
      "         StationId      Date ObsType  ObsValue\n",
      "27343  UK000056225  18641231    PRCP         3\n",
      "27344  ASN00026026  18641231    PRCP         0\n",
      "27345  ASN00089049  18641231    PRCP         0\n",
      "27346  SZ000006717  18641231    TMAX       -62\n",
      "27347  SZ000006717  18641231    TMIN      -105\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.2]\n",
    "\n",
    "# The yearly files are formatted so that every observation \n",
    "#(i.e.,station/year/month/day/element/observation time) is represented by a single row \n",
    "#with the following fields:\n",
    "\n",
    "# station identifier (GHCN Daily Identification Number)\n",
    "# date (yyyymmdd; where yyyy=year; mm=month; and, dd=day)\n",
    "# observation type (see ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt for definitions)\n",
    "# observation value (see ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt for units)\n",
    "# observation time (if available, as hhmm where hh=hour and mm=minutes in local time)\n",
    "\n",
    "columns=['StationId' ,'Date', 'ObsType', 'ObsValue']\n",
    "\n",
    "df = test.iloc[:, :4]\n",
    "df.columns=columns\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **Ex. 4.1.3:**  Select data for the station `ITE00100550` and only observations for maximal temperature. Make a copy of the DataFrame. Explain in a one or two sentences how copying works.\n",
    "\n",
    "> *Hint 1*: the `&` operator works elementwise on boolean series (like `and` in core python).\n",
    "\n",
    "> *Hint 2*: copying of the dataframe is done with the `copy` method for DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       StationId      Date ObsType  ObsValue\n",
      "74   ITE00100550  18640102    TMAX         8\n",
      "151  ITE00100550  18640103    TMAX       -28\n",
      "226  ITE00100550  18640104    TMAX         0\n",
      "304  ITE00100550  18640105    TMAX       -19\n",
      "382  ITE00100550  18640106    TMAX       -13\n",
      "         StationId      Date ObsType  ObsValue\n",
      "26967  ITE00100550  18641227    TMAX        20\n",
      "27042  ITE00100550  18641228    TMAX        63\n",
      "27118  ITE00100550  18641229    TMAX        71\n",
      "27195  ITE00100550  18641230    TMAX        50\n",
      "27271  ITE00100550  18641231    TMAX        33\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.3]\n",
    "station_id = 'ITE00100550'\n",
    "observation_type = 'TMAX'\n",
    "ite0010055_maxtmp_obs = df.loc[(df['StationId'] == station_id) & (df['ObsType'] == observation_type)].copy()\n",
    "print(ite0010055_maxtmp_obs.head())\n",
    "print(ite0010055_maxtmp_obs.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.1.4:** Make a new column called `TMAX_F` where you have converted the temperature variables to Fahrenheit. \n",
    "\n",
    "> *Hint*: Conversion is $F = 32 + 1.8*C$ where $F$ is Fahrenheit and $C$ is Celsius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       StationId      Date ObsType  ObsValue  TMAX_F\n",
      "74   ITE00100550  18640102    TMAX         8    46.4\n",
      "151  ITE00100550  18640103    TMAX       -28   -18.4\n",
      "226  ITE00100550  18640104    TMAX         0    32.0\n",
      "304  ITE00100550  18640105    TMAX       -19    -2.2\n",
      "382  ITE00100550  18640106    TMAX       -13     8.6\n",
      "         StationId      Date ObsType  ObsValue  TMAX_F\n",
      "26967  ITE00100550  18641227    TMAX        20    68.0\n",
      "27042  ITE00100550  18641228    TMAX        63   145.4\n",
      "27118  ITE00100550  18641229    TMAX        71   159.8\n",
      "27195  ITE00100550  18641230    TMAX        50   122.0\n",
      "27271  ITE00100550  18641231    TMAX        33    91.4\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.4]\n",
    "def c_to_f(c: int) -> float:\n",
    "    return 32 + 1.8 * c\n",
    "\n",
    "ite0010055_maxtmp_obs['TMAX_F'] = ite0010055_maxtmp_obs['ObsValue'].apply(c_to_f)\n",
    "print(ite0010055_maxtmp_obs.head())\n",
    "print(ite0010055_maxtmp_obs.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex 4.1.5:**  Inspect the indices, are they following the sequence of natural numbers, 0,1,2,...? If not, reset the index and make sure to drop the old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     StationId      Date ObsType  ObsValue  TMAX_F\n",
      "0  ITE00100550  18640102    TMAX         8    46.4\n",
      "1  ITE00100550  18640103    TMAX       -28   -18.4\n",
      "2  ITE00100550  18640104    TMAX         0    32.0\n",
      "3  ITE00100550  18640105    TMAX       -19    -2.2\n",
      "4  ITE00100550  18640106    TMAX       -13     8.6\n",
      "       StationId      Date ObsType  ObsValue  TMAX_F\n",
      "360  ITE00100550  18641227    TMAX        20    68.0\n",
      "361  ITE00100550  18641228    TMAX        63   145.4\n",
      "362  ITE00100550  18641229    TMAX        71   159.8\n",
      "363  ITE00100550  18641230    TMAX        50   122.0\n",
      "364  ITE00100550  18641231    TMAX        33    91.4\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.5]\n",
    "ite0010055_maxtmp_obs = ite0010055_maxtmp_obs.reset_index(drop=True)\n",
    "print(ite0010055_maxtmp_obs.head())\n",
    "print(ite0010055_maxtmp_obs.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex 4.1.6:** Make a new DataFrame where you have sorted by the maximum temperature. What is the date for the first and last observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    18640117\n",
      "Name: Date, dtype: int64\n",
      "220    18640809\n",
      "Name: Date, dtype: int64\n",
      "\n",
      "18640117\n",
      "18640809\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.6]\n",
    "obs_sorted = ite0010055_maxtmp_obs.sort_values(by=['ObsValue'])\n",
    "#print(obs_sorted.iloc[0, :])\n",
    "#print(obs_sorted.iloc[-1, :])\n",
    "print(obs_sorted.loc[:, 'Date'].head(1))\n",
    "print(obs_sorted.loc[:, 'Date'].tail(1))\n",
    "\n",
    "print()\n",
    "\n",
    "# Alternate using iloc\n",
    "date_column = 1\n",
    "print(obs_sorted.iloc[0, date_column])\n",
    "print(obs_sorted.iloc[-1, date_column])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex 4.1.7:** CSV-files: save your DataFrame as a CSV file. what does index argument do?\n",
    "\n",
    "> Try to save the file using a relative path and an absolut path. \n",
    "With a relative you only specify the file name. This will save the file in the folder you are currently working in. With an absolute path, you specify the whole path, which allows you to save the file in a folder of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.1.7]\n",
    "import os\n",
    "\n",
    "home_path = os.environ['HOME']\n",
    "abs_path = home_path + '/development/SummerSchool/sds_assignments/lecture_exercises/'\n",
    "\n",
    "ite0010055_maxtmp_obs.to_csv('ite0010055_maxtmp_obs.csv')\n",
    "df.to_csv(abs_path + '1864_tmps.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **(Bonus) Ex. 4.1.8**: A very compact way of writing code and making list in Python, is called list comprehensions. Depending on what you are doing, list can be more or less efficient that for example vectorized operations using NumPy. \n",
    "\n",
    ">Read about list comprehenseions online, and use it to make a list with the numbers from 0 to a million (10\\*\\*6), and add 3 to each element. Do the same doing NumPy, and time both methods. Which method is faster? \n",
    "\n",
    "> *Hint 1*: Use the `timeit` package for timing each method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.188841584999977\n",
      "0.17127553000000262\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "num_list = list(range(0, 1000000))\n",
    "\n",
    "list_comp_time = timeit.timeit('[num + 3 for num in range(0, 1000000)]', number=100)\n",
    "np_arange_time = timeit.timeit('import numpy; numpy.arange(0, 1000000) + 3', number=100)\n",
    "\n",
    "print(list_comp_time)\n",
    "print(np_arange_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
